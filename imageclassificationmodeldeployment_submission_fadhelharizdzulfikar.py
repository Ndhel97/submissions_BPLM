# -*- coding: utf-8 -*-
"""imageclassificationmodeldeployment_submission_fadhelharizdzulfikar.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nkIi5T3hppRE1SREJNKWpTN8PecnX_7p

# Image Classification using VGG16

Prepare the environment
"""

import os
os.environ['KAGGLE_CONFIG_DIR'] = "/content/drive/My Drive/Kaggle"

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/My Drive/Kaggle

"""Download dataset"""

!kaggle datasets download -d alessiocorrado99/animals10 --force

"""Unzip dataset"""

!unzip \*.zip -d "/content/drive/My Drive/Kaggle" && rm *.zip

"""Check folders dataset in directory"""

cd raw-img/

ls

"""Count image in each class"""

for folder in os.listdir('/content/drive/My Drive/Kaggle/raw-img'):
  print(folder + ': ' + str(len(os.listdir('/content/drive/My Drive/Kaggle/raw-img/' + str(folder)))))

"""Because Google colab has limited RAM resource for free, I decided to reduce the data by removing some classes."""

! rm -rf gallina
! rm -rf pecora
! rm -rf mucca
! rm -rf farfalla
! rm -rf elefante

"""Check the data again"""

for folder in os.listdir('/content/drive/My Drive/Kaggle/raw-img'):
  print(folder + ': ' + str(len(os.listdir('/content/drive/My Drive/Kaggle/raw-img/' + str(folder)))))

"""So, in this project I will only use 5 classes to categorize the data. There are ragno (spider), cane (dog), cavallo (horse), scoiattolo (squirrel), and gatto (cat)

Next, import Libraries
"""

import numpy as np
import pandas as pd
import tensorflow as tf
import os
import cv2
import matplotlib.pyplot as plt
from tqdm import tqdm_notebook as tqdm
from sklearn.utils import class_weight, shuffle

from keras import applications
from keras import optimizers
from keras.utils import to_categorical
from keras.models import Sequential, Model, load_model
from keras.layers import Dropout, Flatten, Dense
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ModelCheckpoint
from keras.callbacks import EarlyStopping
from matplotlib import pyplot

"""Prepare the data. I use dataframe to to save the list of filename and each category."""

foldernames = os.listdir('/content/drive/My Drive/Kaggle/raw-img')
categories = []
files = []
i = 0
for k, folder in enumerate(foldernames):
    filenames = os.listdir('/content/drive/My Drive/Kaggle/raw-img/' + folder);
    for file in filenames:
        files.append('/content/drive/My Drive/Kaggle/raw-img/' + folder + "/" + file)
        categories.append(k)
        
df = pd.DataFrame({
    'filename': files,
    'category': categories
})
train_df = pd.DataFrame(columns=['filename', 'category'])
for i in range(5):
    train_df = train_df.append(df[df.category == i].iloc[:2500,:])

train_df.head()
train_df = train_df.reset_index(drop=True)
train_df

x = train_df['filename']
y = train_df['category']

x, y = shuffle(x, y, random_state=8)

"""Preprocess the data using cv2 library"""

def centering_image(img):
    size = [166,166]
    
    img_size = img.shape[:2]
    
    # centering
    row = (size[1] - img_size[0]) // 2
    col = (size[0] - img_size[1]) // 2
    resized = np.zeros(list(size) + [img.shape[2]], dtype=np.uint8)
    resized[row:(row + img.shape[0]), col:(col + img.shape[1])] = img

    return resized

images = []
with tqdm(total=len(train_df)) as pbar:
    for i, file_path in enumerate(train_df.filename.values):
        #read image
        img = cv2.imread(file_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        #resize image
        if(img.shape[0] > img.shape[1]):
            tile_size = (int(img.shape[1]*166/img.shape[0]),166)
        else:
            tile_size = (166, int(img.shape[0]*166/img.shape[1]))

        #centering the image
        img = centering_image(cv2.resize(img, dsize=tile_size))

        #output image is 150px*150px
        img = img[8:158, 8:158]
        images.append(img)
        pbar.update(1)

images = np.array(images)

"""Visualize the data"""

rows,cols = 1,5
fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(20,20))
for i in range(5):
    path = train_df[train_df.category == i].values[0]
    axes[i%cols].set_title(path[0].split('/')[-2] + str(path[1]))
    axes[i%cols].imshow(images[train_df[train_df.filename == path[0]].index[0]])

"""Convert data into numpy array"""

data_num = len(y)
random_index = np.random.permutation(data_num)

x_shuffle = []
y_shuffle = []
for i in range(data_num):
    x_shuffle.append(images[random_index[i]])
    y_shuffle.append(y[random_index[i]])
    
x = np.array(x_shuffle) 
y = np.array(y_shuffle)

#Split data into 80% training data and 20% validation data
val_split_num = int(round(0.2*len(y)))
x_train = x[val_split_num:]
y_train = y[val_split_num:]
x_test = x[:val_split_num]
y_test = y[:val_split_num]

print('x_train', x_train.shape)
print('y_train', y_train.shape)
print('x_test', x_test.shape)
print('y_test', y_test.shape)
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255
x_test /= 255

#Change category name
img_rows, img_cols, img_channel = 150, 150, 3
name_animal = []
for i in range(5):
    path = train_df[train_df.category == i].values[0]
    if path[0].split('/')[-2] == 'cavallo':
        name_animal.append('horse')
    elif path[0].split('/')[-2] == 'gatto':
        name_animal.append('cat')
    elif path[0].split('/')[-2] == 'scoiattolo':
        name_animal.append('squirrel')
    elif path[0].split('/')[-2] == 'ragno':
        name_animal.append('spider')
    elif path[0].split('/')[-2] == 'cane':
        name_animal.append('dog')

"""In this project i use VGG16. VGG16 is a convolutional neural network model proposed by K. Simonyan and A. Zisserman from the University of Oxford in the paper “Very Deep Convolutional Networks for Large-Scale Image Recognition”."""

base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_rows, img_cols, img_channel))

add_model = Sequential()
add_model.add(Flatten(input_shape=base_model.output_shape[1:]))
add_model.add(Dense(166, activation='relu'))
add_model.add(Dense(5, activation='softmax'))

model = Model(inputs=base_model.input, outputs=add_model(base_model.output))
model.compile(loss='binary_crossentropy', optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),
              metrics=['accuracy'])

model.summary()

"""Train the model."""

batch_size = 32
epochs = 20
checkpoint_path=f'/content/drive/My Drive/Dicoding/Belajar Pengembangan Machine Learning/testmodel_assignment3.h5'

# Initialize Callback for EarlyStopping
es = EarlyStopping(monitor='val_loss', patience=2, verbose=2) # training will stop if there is no improvement in val_accuracy in 3 epochs
mc = ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, mode='min')

train_datagen = ImageDataGenerator(
        rotation_range=30, 
        width_shift_range=0.1,
        height_shift_range=0.1, 
        horizontal_flip=True)
train_datagen.fit(x_train)


history = model.fit_generator(
    train_datagen.flow(x_train, y_train, batch_size=batch_size),
    steps_per_epoch=x_train.shape[0] // batch_size,
    epochs=epochs,
    validation_data=(x_test, y_test),
    callbacks=[es, mc]
)

# Plot training history
pyplot.plot(history.history['loss'], label='train_loss')
pyplot.plot(history.history['accuracy'], label='train_accuracy')
pyplot.plot(history.history['val_loss'], label='val_loss')
pyplot.plot(history.history['val_accuracy'], label='val_accuracy')
pyplot.legend()
pyplot.show()

"""Test the model"""

test_images = []
j = 40 # change this to get different images
for i in range(5):
    path = train_df[train_df.category == i].values[j]
    a = images[train_df[train_df.filename == path[0]].index[0]]
    img = np.array(a)
    img = img[:, :, ::-1].copy() 
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    if(img.shape[0] > img.shape[1]):
        tile_size = (int(img.shape[1]*166/img.shape[0]),166)
    else:
        tile_size = (166, int(img.shape[0]*166/img.shape[1]))
    img = centering_image(cv2.resize(img, dsize=tile_size))
    img = img[8:158, 8:158]
    test_images.append(img)

test_images = np.array(test_images).reshape(-1,150,150,3)
something = model.predict(test_images)
animals = name_animal
i = 0
for pred in something:
    path = train_df[train_df.category == i].values[2]
    plt.imshow(test_images[i])
    plt.show()
    print('Actual  :', animals[i])
    print('Predict :', animals[np.where(pred.max() == pred)[0][0]])
    i += 1

"""Convert the model to tflite"""

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

cd /content/drive/My Drive/Dicoding/Belajar Pengembangan Machine Learning

"""Save the model"""

with tf.io.gfile.GFile('model.tflite', 'wb') as f:
  f.write(tflite_model)

